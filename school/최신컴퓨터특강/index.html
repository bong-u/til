<!doctype html><html lang=ko>
<head>
<title>최신컴퓨터특강</title>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="1주차 - 원유재 교수님 - 첨단분야 혁신융합대학사업 (COSS: Convergence and Open Sharing System)  추진배경 : 디지털 전환, …">
<meta property="og:site_name" content="bong-u/til">
<meta property="og:title" content="최신컴퓨터특강">
<meta property="og:description" content="1주차 - 원유재 교수님 - 첨단분야 혁신융합대학사업 (COSS: Convergence and Open Sharing System)  추진배경 : 디지털 전환, …">
<meta property="og:type" content="blog">
<meta property="og:url" content="https://github.com/bong-u/til-hugo">
<meta property="og:image" content="https://bong-u.github.io/til/asset/thumbnail.jpg">
<script type=text/javascript src=https://bong-u.github.io/til/script/base.js></script>
<link rel=icon href=https://bong-u.github.io/til/favicon16.png sizes=16x16>
<link rel=icon href=https://bong-u.github.io/til/favicon32.png sizes=32x32>
<link rel=icon href=https://bong-u.github.io/til/favicon48.png sizes=48x48>
<link rel=icon href=https://bong-u.github.io/til/favicon64.png sizes=64x64>
<link id=twCSS rel=stylesheet href=https://bong-u.github.io/til/css/style.css>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HE9FQR1ML7"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-HE9FQR1ML7')</script>
</head>
<body class=custom-scroll>
<div class="flex w-full flex-col items-center">
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script>
<script>MathJax={tex:{inlineMath:[['$','$']]}}</script>
<script type=text/javascript src=https://bong-u.github.io/til/script/single.js></script>
<script type=text/javascript src=https://bong-u.github.io/til/script/toc.js></script>
<header class="flex justify-center p-3 w-full text-lg border-b border-line">
<div class="w-full flex justify-between lg-5/6">
<h3>
<a href=https://bong-u.github.io/til/ class=hover-black>
bong-u/til
</a>
</h3>
<div class="flex gap-5">
<a class=hover-black href=https://bong-u.github.io/til/>
🏠 home
</a>
<a class=hover-black href=https://github.com/bong-u/til>
🐈 repository
</a>
</div>
</div>
</header>
<input type=checkbox id=toggleDarkMode onchange=toggleDarkModeHandler() hidden>
<main class="w-full lg:w-5/6 px-3 sm:px-12">
<aside class="fixed top-0 right-0 my-24 w-1/6 gap-3 px-9 hidden xl:flex text-sm overflow-hidden">
<nav id=TableOfContents>
<ul>
<li><a href=#1주차---원유재-교수님---첨단분야-혁신융합대학사업-coss-convergence-and-open-sharing-system>1주차 - 원유재 교수님 - 첨단분야 혁신융합대학사업 (COSS: Convergence and Open Sharing System)</a>
<ul>
<li><a href=#5개-융복합창의전공>5개 융복합창의전공</a></li>
<li><a href=#25-1학기-충남대학교-개설-과목>25-1학기 충남대학교 개설 과목</a></li>
<li><a href=#학생지원>학생지원</a></li>
</ul>
</li>
<li><a href=#3주차---김형신-교수님>3주차 - 김형신 교수님</a>
<ul>
<li><a href=#ai기술의-임베디드-시스템화>AI기술의 임베디드 시스템화</a></li>
<li><a href=#자율주행-자동차에서의-딥러닝-구현>자율주행 자동차에서의 딥러닝 구현</a></li>
<li><a href=#image-classification>Image Classification</a></li>
<li><a href=#dnn-and-mac-operation>DNN and MAC operation</a></li>
<li><a href=#임베디드-ai-하드웨어>임베디드 AI 하드웨어</a></li>
<li><a href=#실시간-온보드-ai-컴퓨팅>실시간 온보드 AI 컴퓨팅</a></li>
<li><a href=#cesl의-연구>CESL의 연구</a></li>
</ul>
</li>
<li><a href=#4주차---조승범-교수님>4주차 - 조승범 교수님</a>
<ul>
<li><a href=#이론-전산학>이론 전산학</a></li>
<li><a href=#1-integer-sequence-representation>1. Integer Sequence Representation</a></li>
<li><a href=#2-edit-distance>2. Edit Distance</a></li>
<li><a href=#3-optimal-online-binary-search-tree>3. Optimal online binary search tree</a></li>
</ul>
</li>
<li><a href=#4주차---권진근-교수님---rnnlstm>4주차 - 권진근 교수님 - RNN/LSTM</a>
<ul>
<li><a href=#rnn-recurrent-neural-network>RNN (Recurrent Neural Network)</a></li>
<li><a href=#lstm-long-short-term-memory>LSTM (Long Short Term Memory)</a></li>
<li><a href=#attention-network>Attention Network</a></li>
<li><a href=#transformer>Transformer</a></li>
<li><a href=#bert-bidirectional-encoder-representations-from-transformers>BERT (Bidirectional Encoder Representations from Transformers)</a></li>
<li><a href=#bart-bidirectional-and-auto-regressive-transformers>BART (Bidirectional and Auto-Regressive Transformers)</a></li>
<li><a href=#gpt-generative-pre-trained-transformer>GPT (Generative pre-trained transformer)</a></li>
<li><a href=#rag-retrieval-augmented-generation>RAG (Retrieval-Augmented Generation)</a></li>
<li><a href=#open-model-vs-closed-model>Open Model vs Closed Model</a></li>
</ul>
</li>
<li><a href=#5주차---김형기-교수님---컴퓨터-그래픽스-및-혼합현실-기술-소개-및-현황>5주차 - 김형기 교수님 - 컴퓨터 그래픽스 및 혼합현실 기술 소개 및 현황</a></li>
<li><a href=#컴퓨터-그래픽스>컴퓨터 그래픽스</a>
<ul>
<li><a href=#렌더링>렌더링</a></li>
<li><a href=#on-line-rendering-rasterization>On-line Rendering: Rasterization</a></li>
<li><a href=#off-line-rendering-raypath-tracing>Off-line Rendering: Ray/Path Tracing</a></li>
</ul>
</li>
<li><a href=#mixed-reality-혼합현실>Mixed Reality (혼합현실)</a>
<ul>
<li><a href=#용어>용어</a></li>
<li><a href=#buzzword>Buzzword</a></li>
<li><a href=#궁극적인-목표>궁극적인 목표</a></li>
<li><a href=#hmd-head-mounted-display>HMD (Head Mounted Display)</a></li>
</ul>
</li>
<li><a href=#5주차---양희철-교수님---aiml-시스템-연구-동향>5주차 - 양희철 교수님 - AI/ML 시스템 연구 동향</a>
<ul>
<li><a href=#aiml-시스템의-효율성>AI/ML 시스템의 효율성</a></li>
<li><a href=#aiml-시스템의-신뢰성>AI/ML 시스템의 신뢰성</a></li>
</ul>
</li>
<li><a href=#6주차---박지훈-교수님---edge-컴퓨팅-환경-인공지능-응용-연구>6주차 - 박지훈 교수님 - Edge 컴퓨팅 환경 인공지능 응용 연구</a>
<ul>
<li><a href=#edge-computing>Edge Computing</a></li>
<li><a href=#edge-computing의-장점>Edge Computing의 장점</a></li>
<li><a href=#지향하는-것>지향하는 것</a></li>
<li><a href=#연구-과정>연구 과정</a></li>
<li><a href=#multitask-learning>Multitask Learning</a></li>
<li><a href=#각종-연구>각종 연구</a></li>
<li><a href=#이상-탐지>이상 탐지</a></li>
</ul>
</li>
</ul>
</nav>
</aside>
<section class="my-16 xl:w-5/6">
<div class="mb-8 whitespace-nowrap">
<div class="flex justify-between items-baseline my-4 gap-8">
<h1 id=title class="overflow-ellipsis-bundle text-3xl font-bold p-1">
최신컴퓨터특강
</h1>
</div>
</div>
<div class="text-sm flex mb-8 justify-between text-textgray">
<div>
</div>
<h4 id=date>수정일 : 2025-04-14</h4>
</div>
<hr class=opacity-30>
<article data-pagefind-body id=content class="bg-inherit markdown-body flex flex-col">
<h2 id=1주차---원유재-교수님---첨단분야-혁신융합대학사업-coss-convergence-and-open-sharing-system>1주차 - 원유재 교수님 - 첨단분야 혁신융합대학사업 (COSS: Convergence and Open Sharing System)</h2>
<ul>
<li>추진배경 : 디지털 전환, 글로벌 경쟁 심화에 따라 신기술 초격차 확보 및 급증하는 신산업 인력 수요에 대응할 수 있는 인재 양성</li>
<li>충남대학교 : 블록체인 분야 특화, 연구협력(연구단지) 중심 특화</li>
</ul>
<h3 id=5개-융복합창의전공>5개 융복합창의전공</h3>
<ul>
<li>블록체인융합전공</li>
<li>사이버보안융합전공</li>
<li>클라우드융합전공</li>
<li>데이터보안활용융합전공 : 컴퓨터 비전공자 대상</li>
<li>개인정보보호융합전공</li>
</ul>
<h3 id=25-1학기-충남대학교-개설-과목>25-1학기 충남대학교 개설 과목</h3>
<ul>
<li>블록체인 개론</li>
<li>블록체인 프로그래밍</li>
<li>디지털 자산과 블록체인</li>
</ul>
<h3 id=학생지원>학생지원</h3>
<ul>
<li>혁신융합대학 학위 취득</li>
<li>장학금 지원</li>
<li>전문가와 교류 기회</li>
<li>학습기기 지원</li>
<li>현장실습 기회</li>
</ul>
<h2 id=3주차---김형신-교수님>3주차 - 김형신 교수님</h2>
<h3 id=ai기술의-임베디드-시스템화>AI기술의 임베디드 시스템화</h3>
<h4 id=이유>이유</h4>
<ul>
<li>Privacy (개인정보 보호)</li>
<li>Latency (지연시간)</li>
<li>Cost (비용)</li>
</ul>
<h4 id=embedding-resnet>Embedding Resnet</h4>
<blockquote>
<p>Resnet을 임베디드 시스템에 적용함</p>
</blockquote>
<ul>
<li>Resnet : 합성곱 신경망 모델</li>
</ul>
<h3 id=자율주행-자동차에서의-딥러닝-구현>자율주행 자동차에서의 딥러닝 구현</h3>
<h3 id=image-classification>Image Classification</h3>
<h3 id=dnn-and-mac-operation>DNN and MAC operation</h3>
<ul>
<li>DNN : Deep Neural Network</li>
<li>MAC : Multiply and Accumulate</li>
</ul>
<h3 id=임베디드-ai-하드웨어>임베디드 AI 하드웨어</h3>
<h4 id=qualcomm-hexagon-dsp>Qualcomm Hexagon DSP</h4>
<ul>
<li>Performance with low power</li>
<li>고속 MAC 기반 프로세서</li>
</ul>
<h4 id=apple-neural-engine>Apple Neural Engine</h4>
<ul>
<li>뉴럴넷 가속기와 MMA 기반 병렬처리형 GPU 포함</li>
</ul>
<h4 id=nvidia-jetson>Nvidia Jetson</h4>
<ul>
<li>다수의 PE 기반 MMA 가속형 병렬처리 GPU</li>
<li>양자화, 프루닝 하드웨어 지원</li>
<li>최적화 SW 스택 지원</li>
<li>Nvidia Xavier NX 컴퓨터
<blockquote>
<p>Nvidia Jetson 시리즈 중 하나</p>
</blockquote>
</li>
</ul>
<h4 id=tensor-processing-unit-tpu>Tensor Processing Unit (TPU)</h4>
<ul>
<li>Google 사에서 개발한 뉴럴프로세서</li>
<li>검색엔진, 알파고에 사용</li>
</ul>
<h4 id=google-tpu--high-level-architecture>Google TPU : High-level Architecture</h4>
<h4 id=fpga기반-가속기-accelerator>FPGA기반 가속기 (Accelerator)</h4>
<ul>
<li>도메인과 응용에 특화된 가속회로를 FPGA로 구현하고 소프트웨어 스택을 제공</li>
</ul>
<h4 id=microcontrollersmcu>Microcontrollers(MCU)</h4>
<ul>
<li>제어용 임베디드 프로세서로 연산 성능이 매우 낮으며, AI를 위한 가속기능은 없지만, 모델 경량화, 압축을 통해 최적화를 적용</li>
</ul>
<h3 id=실시간-온보드-ai-컴퓨팅>실시간 온보드 AI 컴퓨팅</h3>
<h3 id=cesl의-연구>CESL의 연구</h3>
<ul>
<li>프레임워크 없이 DNN 추론 가능하게 하기
<ul>
<li>PyTorch, Tensorflow 없이</li>
<li>모든 추론 루틴을 C로 구현</li>
</ul>
</li>
<li>실시간 추론
<ul>
<li>메모리 계층을 활용하는 수학 라이브러리 최적화</li>
<li>CPU, GPU, DSP, NPU 최적 워크로드 할당을 통한 계산 가속</li>
</ul>
</li>
<li>NN/LLM 압축
<ul>
<li>속도 향상</li>
<li>정확도 손실 없음</li>
</ul>
</li>
<li>사용하는 프레임워크
<ul>
<li>TensorRT, ONNX RT</li>
<li>Triton, GEMM, llama.cpp</li>
<li>Darknet, OpenCL</li>
</ul>
</li>
</ul>
<h2 id=4주차---조승범-교수님>4주차 - 조승범 교수님</h2>
<h3 id=이론-전산학>이론 전산학</h3>
<blockquote>
<p>수학을 이용하여 다양한 전산학 관련 문제들을 정의하고 이를 해결하는 학문</p>
</blockquote>
<h3 id=1-integer-sequence-representation>1. Integer Sequence Representation</h3>
<blockquote>
<p>알파벳 size가 |A|이고 길이가 n인 integer sequence를 가능한 작은 공간에 저장하기, 단, 일반적인 array 처럼 random acess가 가능해야 함</p>
</blockquote>
<ul>
<li>방법 1: 각 alphabet 마다 4비트씩 할당함 -> 4n bits, O(1) access time</li>
<li>방법 2: 가능한 모든 10^n개의 sequence에 대해 순서대로 숫자를 부여함
$$ \left\lceil \log_2(10^n) \right\rceil = \left\lceil n \cdot \log_2 10 \right\rceil \approx \left\lceil 3.32n \right\rceil \text{ bits} $$
<ul>
<li>O(n) access time</li>
</ul>
</li>
</ul>
<h3 id=2-edit-distance>2. Edit Distance</h3>
<ul>
<li>edit distance : 두 문자열을 같게 만들기 위해 필요한 최소한의 연산 횟수</li>
<li>연산 종류
<ul>
<li>삽입 (Insert)</li>
<li>삭제 (Delete)</li>
<li>대체 (Replace)</li>
</ul>
</li>
<li>SETH가 거짓이 아니면 $O(n^2)$ 보다 빨리 계산할 수 없음</li>
<li>SETH(Strong Exponential Time Hypothesis) : 강한 지수 시간 가설</li>
</ul>
<h3 id=3-optimal-online-binary-search-tree>3. Optimal online binary search tree</h3>
<blockquote>
<p>몰루</p>
</blockquote>
<h2 id=4주차---권진근-교수님---rnnlstm>4주차 - 권진근 교수님 - RNN/LSTM</h2>
<h3 id=rnn-recurrent-neural-network>RNN (Recurrent Neural Network)</h3>
<p>$$ h_t = f(Vx_{t} + Ah_{t-1}) $$</p>
<ul>
<li>f: tanh</li>
<li>$x_t$: 현재 입력</li>
<li>$h_{t-1}$: 과거정보</li>
</ul>
<h3 id=lstm-long-short-term-memory>LSTM (Long Short Term Memory)</h3>
<blockquote>
<p>이전의 입력 정보가 오래 기억되도록 구조 개선</p>
</blockquote>
<h3 id=attention-network>Attention Network</h3>
<blockquote>
<p>디코더에서 출력 단어를 예상하는 매 time step마다, 인코더에서의 전체 인풋을 한 번 더 참고</p>
</blockquote>
<h3 id=transformer>Transformer</h3>
<blockquote>
<p>RNN없이 Attention만으로 Encoder와 Decoder를 설계</p>
</blockquote>
<ul>
<li>
<p>기본 구조 : 다층 구조인 N개의 encoder layer와 N개의 decoder layer로 구성</p>
</li>
<li>
<p>포지셔널 인코딩 (Positional Encoding)</p>
<ul>
<li>RNN은 단어의 위치에 따라 순차적으로 입력을 받아 각 단어의 위치 정보를 가짐</li>
<li>트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니기에 단어의 위치 정보가 필요</li>
</ul>
</li>
<li>
<p>순환을 모두 없애고 self-attention이라는 특별한 형태의 attention에 의지</p>
</li>
</ul>
<h4 id=self-attention>self-attention</h4>
<blockquote>
<p>Attention을 자기자신에게 수행</p>
</blockquote>
<ul>
<li>input data 안에 있는 벡터들 간의 similarities를 계산</li>
</ul>
<h3 id=bert-bidirectional-encoder-representations-from-transformers>BERT (Bidirectional Encoder Representations from Transformers)</h3>
<ul>
<li>Encoder만 사용</li>
</ul>
<h3 id=bart-bidirectional-and-auto-regressive-transformers>BART (Bidirectional and Auto-Regressive Transformers)</h3>
<ul>
<li>Encoder와 Decoder 모두 사용</li>
</ul>
<h3 id=gpt-generative-pre-trained-transformer>GPT (Generative pre-trained transformer)</h3>
<ul>
<li>Decoder만 사용</li>
</ul>
<h4 id=icl-in-context-learning>ICL (In-context Learning)</h4>
<blockquote>
<p>모델이 주어진 예시를 보고 학습하는 것</p>
</blockquote>
<ul>
<li>
<p>ICL은 LM이 패턴의 추상화 능력을 가지고 있다는 것을 보여줌</p>
</li>
<li>
<p>종류</p>
<ul>
<li>Zero-shot : 예시 없음</li>
<li>One-shot : 예시 하나</li>
<li>Few-shot : 예시 여러 개</li>
</ul>
</li>
<li>
<p>Zero-shot chain-of-thought (생각의 사슬)</p>
<blockquote>
<p>&ldquo;Let&rsquo;s think step by step"을 prompt에 삽입 -> GPT의 추론을 유도</p>
</blockquote>
</li>
</ul>
<h3 id=rag-retrieval-augmented-generation>RAG (Retrieval-Augmented Generation)</h3>
<blockquote>
<p>검색 증강 생성</p>
</blockquote>
<h3 id=open-model-vs-closed-model>Open Model vs Closed Model</h3>
<ul>
<li>Open Model : Llama</li>
<li>Closed Model : ChatGPT</li>
</ul>
<h2 id=5주차---김형기-교수님---컴퓨터-그래픽스-및-혼합현실-기술-소개-및-현황>5주차 - 김형기 교수님 - 컴퓨터 그래픽스 및 혼합현실 기술 소개 및 현황</h2>
<h2 id=컴퓨터-그래픽스>컴퓨터 그래픽스</h2>
<h3 id=렌더링>렌더링</h3>
<blockquote>
<p>데이터로부터 이미지를 만들어내는 기술</p>
</blockquote>
<ul>
<li>On-line Rendering : 실시간(>30fps)으로 이미지를 만들어내는 기술</li>
<li>Off-line Rendering : 비실시간으로 이미지를 만들어내는 기술</li>
</ul>
<h3 id=on-line-rendering-rasterization>On-line Rendering: Rasterization</h3>
<ul>
<li>
<p>컴퓨터 그래픽에서, 모든 물체는 삼각형의 집합으로 표현됨</p>
</li>
<li>
<p>이러한 삼각형들을 일련의 과정을 거쳐 화면상 픽셀로 변환하는 방식</p>
</li>
<li>
<p>Vertex Shader : 어디에 삼각형이 있을 것인가?</p>
</li>
<li>
<p>Fragment Shader : 삼각형 안의 픽셀을 어떤 색으로 칠할 것인가?</p>
</li>
<li>
<p>순서 : vertex shader -> rasterization -> fragment shader -> output merger</p>
</li>
</ul>
<h4 id=gpugraphics-processing-unit>GPU(Graphics Processing Unit)</h4>
<ul>
<li>간단한 계산을 할 수 있는 처리 장치 수천-수만개가 동시에 동시에 셰이더를 실행</li>
</ul>
<h3 id=off-line-rendering-raypath-tracing>Off-line Rendering: Ray/Path Tracing</h3>
<h4 id=raypath-tracing>Ray/Path Tracing</h4>
<blockquote>
<p>빛과 물체의 상호작용을 Rasterization 상세히 계산</p>
</blockquote>
<ul>
<li>눈으로 들어올 광선을 역으로 추적하여 색상을 계산</li>
</ul>
<h4 id=rtx-hybrid-rendering>RTX Hybrid Rendering</h4>
<blockquote>
<p>Rasterization + Ray Tracing, 별도의 코어 사용, 딥러닝 기반 기술 적용</p>
</blockquote>
<h2 id=mixed-reality-혼합현실>Mixed Reality (혼합현실)</h2>
<h3 id=용어>용어</h3>
<ul>
<li>현실(Real Environment) : 우리가 살고있는, 물리적 실체가 있는 환경</li>
<li>가상 현실 (Virtual Reality) : 물리적으로 존재하지 않는, 가상으로 만들어진 환경</li>
<li>증강 현실 (Augmented Reality) : 물리적 현실을 배경으로 가상의 객체를 증강시킨 환경</li>
<li>혼합 현실 (Mixed Reality) : 물리적 현실과 가상의 객체가 혼재되어 있는 환경 (AR의 확장 형태)</li>
</ul>
<h3 id=buzzword>Buzzword</h3>
<ul>
<li>확장 현실(eXtended Reality) : MR을 VR까지 확장한 개념</li>
<li>공간 컴퓨팅 (Spatial Computing) : Apple에서 제안한, 메타버스와 디지털 트윈까지 포함하는 개념</li>
</ul>
<h3 id=궁극적인-목표>궁극적인 목표</h3>
<ul>
<li>인간의 주요 감각들을 통해 진짜처럼 느끼게 하는 것</li>
</ul>
<h3 id=hmd-head-mounted-display>HMD (Head Mounted Display)</h3>
<blockquote>
<p>상업적으로 가장 성공한 VR 장치의 형태</p>
</blockquote>
<ul>
<li>XR로의 확장이 가능하도록 전면부의 카메라로 촬영된 영상을 다시 디스플레이에 투사</li>
</ul>
<h4 id=hmd의-원리>HMD의 원리</h4>
<ul>
<li>작은 고해상도 디스플레이가 눈 앞에 있음 -> 초점을 맞출 수 없음</li>
<li><strong>렌즈(돋보기)를 사용하여 상을 멀리 두며, 높은 시야각을 제공할 수 있도록 함</strong></li>
<li>양안 시차를 사용해 거리를 인지할 수 있도록 해당 장치를 제공</li>
</ul>
<h4 id=hmd의-tracking>HMD의 Tracking</h4>
<ul>
<li>Outside-in Tracking : 외부 센서가 HMD 장치를 관찰하여 트래킹</li>
<li>Inside-out Tracking : HMD에 설치된 센서들로 외부를 관찰하여 트래킹</li>
</ul>
<h4 id=xr-hmd>XR HMD</h4>
<ul>
<li>Optical see-through : 반투명한 디스플레이 내부에서 빛을 반사하여 전달</li>
<li>Video see-through : 전면부의 카메라로 찍은 이미지에 가상의 물체를 더해 렌더링</li>
</ul>
<h2 id=5주차---양희철-교수님---aiml-시스템-연구-동향>5주차 - 양희철 교수님 - AI/ML 시스템 연구 동향</h2>
<h3 id=aiml-시스템의-효율성>AI/ML 시스템의 효율성</h3>
<ul>
<li>
<p>Distributed Training</p>
<blockquote>
<p>현실에서는 hybrid parallelism을 사용</p>
</blockquote>
<ul>
<li>Data Parallelism : 데이터를 나누어 각 노드에서 학습</li>
<li>Model/Pipeline Parallelism : 모델을 나누어 각 노드에서 학습</li>
<li>Tensor parallelism : 텐서를 나누어 각 노드에서 학습</li>
<li>Sequence parallelism : 토큰을 나누어 각 노드에서 학습</li>
</ul>
</li>
</ul>
<h3 id=aiml-시스템의-신뢰성>AI/ML 시스템의 신뢰성</h3>
<h4 id=data-privacy>Data Privacy</h4>
<blockquote>
<p>클라우드나 엣지에서 학습이 이루어지는 경우, 데이터가 유출될 수 있음</p>
</blockquote>
<ul>
<li>Distributed Learning
<ul>
<li>Federated Learning : 데이터는 클라우드에 두고, 모델만 엣지에서 학습
<ol>
<li>서버가 장치에 모델을 전송</li>
<li>사용자의 데이터로 장치에서 모델이 학습</li>
<li>각 장치가 모델을 N번 업데이트</li>
<li>업데이트 된 모델이 서버에 전송</li>
<li>모델이 서버에서 합쳐졌다가, 다시 장치에 전송</li>
</ol>
</li>
<li>Split Learning
<ul>
<li>Centralized and distributed neural network training</li>
<li>Peer-to-peer training for distributed learning</li>
</ul>
</li>
<li>Decentralized Learning
<ul>
<li>Swarm learning</li>
<li>Gossip Learning</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id=model-fairness>Model Fairness</h4>
<blockquote>
<p>모델이 특정 집단에 대해 편향되지 않도록 하는 것</p>
</blockquote>
<h4 id=reliability>Reliability</h4>
<ul>
<li>Machine Unlearning</li>
</ul>
<blockquote>
<p>모델이 특정 데이터를 잊도록 하는 것</p>
</blockquote>
<h4 id=robustness>Robustness</h4>
<blockquote>
<p>Model Poisoning에 대한 방어</p>
</blockquote>
<h2 id=6주차---박지훈-교수님---edge-컴퓨팅-환경-인공지능-응용-연구>6주차 - 박지훈 교수님 - Edge 컴퓨팅 환경 인공지능 응용 연구</h2>
<h3 id=edge-computing>Edge Computing</h3>
<blockquote>
<p>중앙 서버 대신 Edge 컴퓨터가 데이터가 생성되는 곳 혹은 처리가 필요한 곳 근처에서 데이터를 처리하는 개념</p>
</blockquote>
<h3 id=edge-computing의-장점>Edge Computing의 장점</h3>
<ul>
<li>지연시간 적음 -> 데이터를 중앙 서버에 보낼 필요 없음, 처리된 결과를 기다릴 필요 없음</li>
<li>통신 연결 불필요</li>
<li>네트워크 트래픽 감소</li>
<li>높은 확장성 -> 센서/플랫폼 수를 늘리는 부담이 적음</li>
<li>개인정보 및 보안 강화 -> 민감한 데이터를 전송할 필요 없음</li>
</ul>
<h3 id=지향하는-것>지향하는 것</h3>
<ul>
<li>데이터를 더 수집하지 않고 동일한 모델에서 정확도를 높이고 싶다 -> 데이터 증강/생성</li>
<li>동일한 속도, 성능에 더 높은 정확도를 얻고 싶다 -> 모델 구조 개선</li>
</ul>
<h3 id=연구-과정>연구 과정</h3>
<ul>
<li>가설 -> 실험 설계 -> 실험 수행 -> 결과 분석</li>
</ul>
<h3 id=multitask-learning>Multitask Learning</h3>
<blockquote>
<p>하나의 모델이 여러 개의 task를 동시에 학습하는 방법</p>
</blockquote>
<h3 id=각종-연구>각종 연구</h3>
<h4 id=데이터-증강>데이터 증강</h4>
<blockquote>
<p>기존에 획득된 데이터를 이용해 데이터에 변형을 가하여 모델의 일반화 성능을 높이는 방법</p>
</blockquote>
<h4 id=가상-데이터-생성활용>가상 데이터 생성/활용</h4>
<blockquote>
<p>현실과 유사한 가상 데이터를 활용하여 학습한 모델을 현실에 적용</p>
</blockquote>
<h4 id=정보-융합>정보 융합</h4>
<ul>
<li>어떤 순간적인 정보를 잘 분석하는 알고리즘을 만듦</li>
</ul>
<h3 id=이상-탐지>이상 탐지</h3>
<ul>
<li>Reconstruction 기반 : 입력 데이터를 차원 축소 -> 차원 확장하여 복원 가능성으로 복원 불가능한 경우/복원 데이터와 원본 차이가 큰 경우 이상으로 판별</li>
<li>Prediction 기반 : 입력 데이터를 기반으로 미래를 예측 -> 해당 예측과 실제 값의 차이가 큰 경우 이상으로 탐지</li>
<li>Representation 기반 : 특정 표현 공간으로 데이터 맵핑 -> 표현 공간에서의 거리/밀도 기반으로 클러스터에서 벗어난 데이터를 이상으로 탐지</li>
</ul>
</article>
<div id=" meta" class=my-16>
<div>
<div class="flex justify-between w-full text-lg">
<a class="previous mr-5 overflow-ellipsis-bundle hover-bold" href=/til/school/network_security/>
<span class=mx-3>◀</span>
네트워크 보안
</a>
</div>
</div>
</div>
<div id=comment-box></div>
</section>
</main>
</div>
</body>
</html>