---
title: "최신컴퓨터특강"
date: 2025-04-14
tags: []
---

## 1주차 - 원유재 교수님 - 첨단분야 혁신융합대학사업 (COSS: Convergence and Open Sharing System)
- 추진배경 : 디지털 전환, 글로벌 경쟁 심화에 따라 신기술 초격차 확보 및 급증하는 신산업 인력 수요에 대응할 수 있는 인재 양성
- 충남대학교 : 블록체인 분야 특화, 연구협력(연구단지) 중심 특화
 
### 5개 융복합창의전공
  - 블록체인융합전공
  - 사이버보안융합전공
  - 클라우드융합전공
  - 데이터보안활용융합전공 : 컴퓨터 비전공자 대상
  - 개인정보보호융합전공
 
### 25-1학기 충남대학교 개설 과목
  - 블록체인 개론
  - 블록체인 프로그래밍
  - 디지털 자산과 블록체인

### 학생지원
- 혁신융합대학 학위 취득
- 장학금 지원
- 전문가와 교류 기회
- 학습기기 지원
- 현장실습 기회

## 3주차 - 김형신 교수님

### AI기술의 임베디드 시스템화

#### 이유
- Privacy (개인정보 보호)
- Latency (지연시간)
- Cost (비용)

#### Embedding Resnet
> Resnet을 임베디드 시스템에 적용함

- Resnet : 합성곱 신경망 모델

### 자율주행 자동차에서의 딥러닝 구현

### Image Classification

### DNN and MAC operation
- DNN : Deep Neural Network
- MAC : Multiply and Accumulate


### 임베디드 AI 하드웨어
#### Qualcomm Hexagon DSP
- Performance with low power
- 고속 MAC 기반 프로세서

#### Apple Neural Engine
- 뉴럴넷 가속기와 MMA 기반 병렬처리형 GPU 포함

#### Nvidia Jetson
- 다수의 PE 기반 MMA 가속형 병렬처리 GPU
- 양자화, 프루닝 하드웨어 지원
- 최적화 SW 스택 지원
- Nvidia Xavier NX 컴퓨터
  > Nvidia Jetson 시리즈 중 하나
     
#### Tensor Processing Unit (TPU)
- Google 사에서 개발한 뉴럴프로세서
- 검색엔진, 알파고에 사용

#### Google TPU : High-level Architecture

#### FPGA기반 가속기 (Accelerator)
- 도메인과 응용에 특화된 가속회로를 FPGA로 구현하고 소프트웨어 스택을 제공

#### Microcontrollers(MCU)
- 제어용 임베디드 프로세서로 연산 성능이 매우 낮으며, AI를 위한 가속기능은 없지만, 모델 경량화, 압축을 통해 최적화를 적용
  
### 실시간 온보드 AI 컴퓨팅

### CESL의 연구
- 프레임워크 없이 DNN 추론 가능하게 하기
  - PyTorch, Tensorflow 없이
  - 모든 추론 루틴을 C로 구현
- 실시간 추론
  - 메모리 계층을 활용하는 수학 라이브러리 최적화
  - CPU, GPU, DSP, NPU 최적 워크로드 할당을 통한 계산 가속
- NN/LLM 압축
  - 속도 향상
  - 정확도 손실 없음
- 사용하는 프레임워크
  - TensorRT, ONNX RT
  - Triton, GEMM, llama.cpp
  - Darknet, OpenCL

## 4주차 - 조승범 교수님

### 이론 전산학
> 수학을 이용하여 다양한 전산학 관련 문제들을 정의하고 이를 해결하는 학문

### 1. Integer Sequence Representation
> 알파벳 size가 |A|이고 길이가 n인 integer sequence를 가능한 작은 공간에 저장하기, 단, 일반적인 array 처럼 random acess가 가능해야 함

- 방법 1: 각 alphabet 마다 4비트씩 할당함 -> 4n bits, O(1) access time
- 방법 2: 가능한 모든 10^n개의 sequence에 대해 순서대로 숫자를 부여함
    $$ \left\lceil \log_2(10^n) \right\rceil = \left\lceil n \cdot \log_2 10 \right\rceil \approx \left\lceil 3.32n \right\rceil \text{ bits} $$
    - O(n) access time

### 2. Edit Distance
- edit distance : 두 문자열을 같게 만들기 위해 필요한 최소한의 연산 횟수
- 연산 종류
  - 삽입 (Insert)
  - 삭제 (Delete)
  - 대체 (Replace)
- SETH가 거짓이 아니면 $O(n^2)$ 보다 빨리 계산할 수 없음
- SETH(Strong Exponential Time Hypothesis) : 강한 지수 시간 가설

### 3. Optimal online binary search tree
> 몰루

## 4주차 - 권진근 교수님 - RNN/LSTM

### RNN (Recurrent Neural Network)

$$ h_t = f(Vx_{t} + Ah_{t-1}) $$
- f: tanh
- $x_t$: 현재 입력
- $h_{t-1}$: 과거정보

### LSTM (Long Short Term Memory)
> 이전의 입력 정보가 오래 기억되도록 구조 개선

### Attention Network
> 디코더에서 출력 단어를 예상하는 매 time step마다, 인코더에서의 전체 인풋을 한 번 더 참고

### Transformer
> RNN없이 Attention만으로 Encoder와 Decoder를 설계

- 기본 구조 : 다층 구조인 N개의 encoder layer와 N개의 decoder layer로 구성
- 포지셔널 인코딩 (Positional Encoding)
  - RNN은 단어의 위치에 따라 순차적으로 입력을 받아 각 단어의 위치 정보를 가짐
  - 트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니기에 단어의 위치 정보가 필요

- 순환을 모두 없애고 self-attention이라는 특별한 형태의 attention에 의지

#### self-attention
> Attention을 자기자신에게 수행
- input data 안에 있는 벡터들 간의 similarities를 계산

### BERT (Bidirectional Encoder Representations from Transformers)
- Encoder만 사용

### BART (Bidirectional and Auto-Regressive Transformers)
- Encoder와 Decoder 모두 사용

### GPT (Generative pre-trained transformer)
- Decoder만 사용

#### ICL (In-context Learning)
> 모델이 주어진 예시를 보고 학습하는 것

- ICL은 LM이 패턴의 추상화 능력을 가지고 있다는 것을 보여줌
- 종류
  - Zero-shot : 예시 없음
  - One-shot : 예시 하나
  - Few-shot : 예시 여러 개

- Zero-shot chain-of-thought (생각의 사슬)
  > "Let's think step by step"을 prompt에 삽입 -> GPT의 추론을 유도

### RAG (Retrieval-Augmented Generation)
> 검색 증강 생성

### Open Model vs Closed Model
- Open Model : Llama
- Closed Model : ChatGPT

## 5주차 - 김형기 교수님 - 컴퓨터 그래픽스 및 혼합현실 기술 소개 및 현황

## 컴퓨터 그래픽스
### 렌더링
> 데이터로부터 이미지를 만들어내는 기술
- On-line Rendering : 실시간(>30fps)으로 이미지를 만들어내는 기술
- Off-line Rendering : 비실시간으로 이미지를 만들어내는 기술

### On-line Rendering: Rasterization
- 컴퓨터 그래픽에서, 모든 물체는 삼각형의 집합으로 표현됨
- 이러한 삼각형들을 일련의 과정을 거쳐 화면상 픽셀로 변환하는 방식
- Vertex Shader : 어디에 삼각형이 있을 것인가?
- Fragment Shader : 삼각형 안의 픽셀을 어떤 색으로 칠할 것인가?

- 순서 : vertex shader -> rasterization -> fragment shader -> output merger

#### GPU(Graphics Processing Unit)
- 간단한 계산을 할 수 있는 처리 장치 수천-수만개가 동시에 동시에 셰이더를 실행

### Off-line Rendering: Ray/Path Tracing

#### Ray/Path Tracing
> 빛과 물체의 상호작용을 Rasterization 상세히 계산
- 눈으로 들어올 광선을 역으로 추적하여 색상을 계산

#### RTX Hybrid Rendering
> Rasterization + Ray Tracing, 별도의 코어 사용, 딥러닝 기반 기술 적용

## Mixed Reality (혼합현실)
### 용어
- 현실(Real Environment) : 우리가 살고있는, 물리적 실체가 있는 환경
- 가상 현실 (Virtual Reality) : 물리적으로 존재하지 않는, 가상으로 만들어진 환경
- 증강 현실 (Augmented Reality) : 물리적 현실을 배경으로 가상의 객체를 증강시킨 환경
- 혼합 현실 (Mixed Reality) : 물리적 현실과 가상의 객체가 혼재되어 있는 환경 (AR의 확장 형태)

### Buzzword
- 확장 현실(eXtended Reality) : MR을 VR까지 확장한 개념
- 공간 컴퓨팅 (Spatial Computing) : Apple에서 제안한, 메타버스와 디지털 트윈까지 포함하는 개념

### 궁극적인 목표
- 인간의 주요 감각들을 통해 진짜처럼 느끼게 하는 것

### HMD (Head Mounted Display)
> 상업적으로 가장 성공한 VR 장치의 형태
- XR로의 확장이 가능하도록 전면부의 카메라로 촬영된 영상을 다시 디스플레이에 투사

#### HMD의 원리
- 작은 고해상도 디스플레이가 눈 앞에 있음 -> 초점을 맞출 수 없음
- **렌즈(돋보기)를 사용하여 상을 멀리 두며, 높은 시야각을 제공할 수 있도록 함**
- 양안 시차를 사용해 거리를 인지할 수 있도록 해당 장치를 제공

#### HMD의 Tracking
- Outside-in Tracking : 외부 센서가 HMD 장치를 관찰하여 트래킹
- Inside-out Tracking : HMD에 설치된 센서들로 외부를 관찰하여 트래킹

#### XR HMD
- Optical see-through : 반투명한 디스플레이 내부에서 빛을 반사하여 전달
- Video see-through : 전면부의 카메라로 찍은 이미지에 가상의 물체를 더해 렌더링

## 5주차 - 양희철 교수님 - AI/ML 시스템 연구 동향

### AI/ML 시스템의 효율성
- Distributed Training
  > 현실에서는 hybrid parallelism을 사용

  - Data Parallelism : 데이터를 나누어 각 노드에서 학습
  - Model/Pipeline Parallelism : 모델을 나누어 각 노드에서 학습
  - Tensor parallelism : 텐서를 나누어 각 노드에서 학습
  - Sequence parallelism : 토큰을 나누어 각 노드에서 학습

### AI/ML 시스템의 신뢰성

#### Data Privacy
> 클라우드나 엣지에서 학습이 이루어지는 경우, 데이터가 유출될 수 있음
- Distributed Learning
  - Federated Learning : 데이터는 클라우드에 두고, 모델만 엣지에서 학습
    1. 서버가 장치에 모델을 전송
    2. 사용자의 데이터로 장치에서 모델이 학습
    3. 각 장치가 모델을 N번 업데이트
    4. 업데이트 된 모델이 서버에 전송
    5. 모델이 서버에서 합쳐졌다가, 다시 장치에 전송
  - Split Learning
    - Centralized and distributed neural network training
    - Peer-to-peer training for distributed learning
  - Decentralized Learning
    - Swarm learning
    - Gossip Learning

#### Model Fairness
> 모델이 특정 집단에 대해 편향되지 않도록 하는 것

#### Reliability
- Machine Unlearning
> 모델이 특정 데이터를 잊도록 하는 것

#### Robustness
> Model Poisoning에 대한 방어

## 6주차 - 박지훈 교수님 - Edge 컴퓨팅 환경 인공지능 응용 연구

### Edge Computing
> 중앙 서버 대신 Edge 컴퓨터가 데이터가 생성되는 곳 혹은 처리가 필요한 곳 근처에서 데이터를 처리하는 개념

### Edge Computing의 장점
- 지연시간 적음 -> 데이터를 중앙 서버에 보낼 필요 없음, 처리된 결과를 기다릴 필요 없음
- 통신 연결 불필요
- 네트워크 트래픽 감소
- 높은 확장성 -> 센서/플랫폼 수를 늘리는 부담이 적음
- 개인정보 및 보안 강화 -> 민감한 데이터를 전송할 필요 없음

### 지향하는 것
- 데이터를 더 수집하지 않고 동일한 모델에서 정확도를 높이고 싶다 -> 데이터 증강/생성
- 동일한 속도, 성능에 더 높은 정확도를 얻고 싶다 -> 모델 구조 개선

### 연구 과정
- 가설 -> 실험 설계 -> 실험 수행 -> 결과 분석

### Multitask Learning
> 하나의 모델이 여러 개의 task를 동시에 학습하는 방법

### 각종 연구
#### 데이터 증강
> 기존에 획득된 데이터를 이용해 데이터에 변형을 가하여 모델의 일반화 성능을 높이는 방법

#### 가상 데이터 생성/활용
> 현실과 유사한 가상 데이터를 활용하여 학습한 모델을 현실에 적용

#### 정보 융합
- 어떤 순간적인 정보를 잘 분석하는 알고리즘을 만듦


### 이상 탐지
- Reconstruction 기반 : 입력 데이터를 차원 축소 -> 차원 확장하여 복원 가능성으로 복원 불가능한 경우/복원 데이터와 원본 차이가 큰 경우 이상으로 판별
- Prediction 기반 : 입력 데이터를 기반으로 미래를 예측 -> 해당 예측과 실제 값의 차이가 큰 경우 이상으로 탐지
- Representation 기반 : 특정 표현 공간으로 데이터 맵핑 -> 표현 공간에서의 거리/밀도 기반으로 클러스터에서 벗어난 데이터를 이상으로 탐지


